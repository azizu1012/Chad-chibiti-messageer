import asyncio
import requests
import json
import re
import os
from datetime import datetime, timedelta
from config import CITY, WEATHER_API_KEY, WEATHER_CACHE_PATH
from serpapi import GoogleSearch  # SerpAPI (d√πng google-search-results package)
from tavily import TavilyClient  # Tavily
import exa_py  # Exa.ai (exa-py package)
from google.generativeai.types import Tool, FunctionDeclaration
from logging_setup import logger
from config import CITY_NAME_MAP  # <-- ƒê√£ di chuy·ªÉn/th√™m v√†o ƒë√¢y
from config import NOTE_PATH
import aiofiles
from config import (
    GOOGLE_CSE_ID,
    GOOGLE_CSE_API_KEY,
    GOOGLE_CSE_ID_1,
    GOOGLE_CSE_API_KEY_1,
    GOOGLE_CSE_ID_2,
    GOOGLE_CSE_API_KEY_2,
    SERPAPI_API_KEY,
    TAVILY_API_KEY,
    EXA_API_KEY,
)
SEARCH_LOCK = asyncio.Lock()
SEARCH_API_COUNTER = 0


weather_lock = asyncio.Lock()
async def get_weather(city_query=None):
    """L·∫•y th·ªùi ti·∫øt current + 6 ng√†y forecast, cache 1 gi·ªù. Lu√¥n tr·∫£ dict."""
    async with weather_lock:
        # N·∫øu kh√¥ng truy·ªÅn city_query th√¨ l·∫•y t·ª´ .env
        city_env = CITY or "Ho Chi Minh City"
        city_query = city_query or city_env
        city_en, city_vi = normalize_city_name(city_query)

        # T·∫°o cache ri√™ng cho t·ª´ng th√†nh ph·ªë
        cache_path = WEATHER_CACHE_PATH.replace(".json", f"_{city_en.replace(' ', '_').lower()}.json")

        # Ki·ªÉm tra cache
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r') as f:
                    cache = json.load(f)
                cache_time = datetime.fromisoformat(cache['timestamp'])
                if datetime.now() - cache_time < timedelta(hours=1):
                    return {**cache['data'], "city_vi": city_vi}  # Tr·∫£ cache n·∫øu <1h
            except:
                pass

        # G·ªçi API n·∫øu cache c≈© ho·∫∑c kh√¥ng c√≥
        if not WEATHER_API_KEY:
            default_data = {
                'current': f'M∆∞a r√†o s√°ng, m√¢y chi·ªÅu ·ªü {city_vi} (23-28¬∞C).',
                'forecast': [f'Ng√†y mai: N·∫Øng, 26¬∞C', f'Ng√†y kia: M∆∞a, 25¬∞C'] * 3,
                'timestamp': datetime.now().isoformat(),
                'city_vi': city_vi
            }
            with open(cache_path, 'w') as f:
                json.dump({'data': default_data, 'timestamp': datetime.now().isoformat()}, f)
            return default_data

        try:
            url = f"http://api.weatherapi.com/v1/forecast.json?key={WEATHER_API_KEY}&q={city_en}&days=7&aqi=no&alerts=no"
            response = requests.get(url, timeout=10)
            if response.status_code != 200:
                raise ValueError(f"API status: {response.status_code}")

            data = response.json()
            if 'error' in data:
                raise ValueError(f"API error: {data['error']['message']}")

            current = data['current']['condition']['text'] + f" ({data['current']['temp_c']}¬∞C)"
            forecast = []
            for day in data['forecast']['forecastday'][1:7]:
                forecast.append(f"Ng√†y {day['date']}: {day['day']['condition']['text']} ({day['day']['avgtemp_c']}¬∞C)")

            weather_data = {
                'current': current,
                'forecast': forecast,
                'timestamp': datetime.now().isoformat(),
                'city_vi': city_vi
            }

            cache_entry = {'data': weather_data, 'timestamp': datetime.now().isoformat()}
            with open(cache_path, 'w') as f:
                json.dump(cache_entry, f, indent=2)

            return weather_data
        except Exception as e:
            logger.error(f"Weather API l·ªói: {e}")
            fallback_data = {
                'current': f'L·ªói API, d√πng m·∫∑c ƒë·ªãnh: M∆∞a r√†o ·ªü {city_vi}, 23-28¬∞C.',
                'forecast': [f'Ng√†y mai: N·∫Øng, 26¬∞C', f'Ng√†y kia: M∆∞a, 25¬∞C'] * 3,
                'timestamp': datetime.now().isoformat(),
                'city_vi': city_vi
            }
            with open(cache_path, 'w') as f:
                json.dump({'data': fallback_data, 'timestamp': datetime.now().isoformat()}, f)
            return fallback_data

async def save_note(query):  # Thay def th√†nh async def
    try:
        note = query.lower().replace("ghi note: ", "").replace("save note: ", "").strip()
        async with aiofiles.open(NOTE_PATH, 'a', encoding='utf-8') as f:
            await f.write(f"[{datetime.now().isoformat()}] {note}\n")
        return f"ƒê√£ ghi note: {note}"
    except PermissionError:
        return "L·ªói: Kh√¥ng c√≥ quy·ªÅn ghi file notes.txt!"
    except Exception as e:
        return f"L·ªói ghi note: {str(e)}"

# -------------------------------------------------------------------------
# SEARCH API: 3x CSE (M·∫∑c ƒë·ªãnh) HO·∫∂C CSE2 b·ªã thay th·∫ø b·∫±ng Fallback (theo l·ªánh AI)
# -------------------------------------------------------------------------
async def run_search_apis(query, mode="general"):
    logger.info(f"CALLING 3x CSE SMART SEARCH for '{query}' (mode: {mode})")
    global SEARCH_API_COUNTER

    # --- [1] L√†m s·∫°ch & t√°ch query ---
    # Ki·ªÉm tra m√£ kh√≥a ·∫©n [FORCE FALLBACK] ngay t·ª´ ƒë·∫ßu
    FORCE_FALLBACK_REQUEST = "[FORCE FALLBACK]" in query.upper()
    
    # D√πng query g·ªëc (ho·∫∑c ƒë√£ l√†m s·∫°ch) ƒë·ªÉ t√°ch sub_queries
    q_base = query.replace("[FORCE FALLBACK]", "").strip()
    
    sub_queries = []
    if " v√† " in q_base or " and " in q_base.lower() or "," in q_base:
        splitters = re.split(r"\s*(?:v√†|and|,)\s*", q_base, flags=re.IGNORECASE)
        sub_queries = [q.strip() for q in splitters if q.strip()]
    else:
        sub_queries = [q_base.strip()]

    # --- [2] M·ªü r·ªông query th√¥ng minh ---
    enriched_queries = []
    for q in sub_queries:
        # Th√™m l·∫°i logic FORCE_FALLBACK v√†o query n·∫øu c√≥, ƒë·ªÉ n√≥ ƒë∆∞·ª£c ki·ªÉm tra l·∫°i ·ªü b∆∞·ªõc 3
        q_enhanced = (
            f"{q} official update release date patch notes roadmap leaks OR speculation"
        )
        if FORCE_FALLBACK_REQUEST:
             # N·∫øu AI y√™u c·∫ßu, th√™m tag v√†o enhanced query
            q_enhanced += " [FORCE FALLBACK]" 
        
        enriched_queries.append(q_enhanced)

    final_results = []

    # --- [3] Ch·∫°y t·ª´ng subquery ---
    for q in enriched_queries:
        async with SEARCH_LOCK:
            # Log ch·ªâ hi·ªán th·ªã query ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch ƒë·ªÉ log ƒë·∫πp h∆°n
            log_q = q.replace(" [FORCE FALLBACK]", "")
            logger.info(f"Running parallel search for subquery: '{log_q}'")

            # 3 CSE ch·∫°y song song
            cse0_task = asyncio.create_task(
                _search_cse(log_q, GOOGLE_CSE_ID, GOOGLE_CSE_API_KEY, 0, start_idx=1)
            )
            cse1_task = asyncio.create_task(
                _search_cse(log_q, GOOGLE_CSE_ID_1, GOOGLE_CSE_API_KEY_1, 1, start_idx=4)
            )
            cse2_task = asyncio.create_task(
                _search_cse(log_q, GOOGLE_CSE_ID_2, GOOGLE_CSE_API_KEY_2, 2, start_idx=7)
            )

            cse0_result, cse1_result, cse2_result = await asyncio.gather(
                cse0_task, cse1_task, cse2_task, return_exceptions=True
            )

            def safe_result(r, name):
                if isinstance(r, Exception):
                    logger.error(f"{name} l·ªói: {r}")
                    return ""
                return r or ""

            cse0_result = safe_result(cse0_result, "CSE0")
            cse1_result = safe_result(cse1_result, "CSE1")
            cse2_result = safe_result(cse2_result, "CSE2")

            # --- D√íNG B·ªî SUNG: Ki·ªÉm tra AI c√≥ y√™u c·∫ßu FORCE FALLBACK hay kh√¥ng ---
            if "[FORCE FALLBACK]" in q.upper() and cse2_result:
                # Logic m·ªõi: CSE2 c√≥ d·ªØ li·ªáu (kh√¥ng r·ªóng), nh∆∞ng AI ƒë√°nh gi√° l√† R√ÅC (y√™u c·∫ßu fallback)
                logger.warning(
                    f"AI y√™u c·∫ßu [FORCE FALLBACK] ‚Üí B·ªè qua CSE2 (c√≥ d·ªØ li·ªáu r√°c), ch·∫°y Fallback thay th·∫ø."
                )
                # Ch·∫°y fallback v·ªõi query ƒë√£ l√†m s·∫°ch
                cse2_result = await _run_fallback_search(log_q)
                
            # --- Logic c≈©: fallback cho CSE2 n·∫øu r·ªóng ---
            elif not cse2_result:
                logger.warning("CSE2 r·ªóng/l·ªói ‚Üí fallback qua SerpAPI/Tavily/Exa")
                cse2_result = await _run_fallback_search(log_q)

            # --- G·ªôp & l·ªçc tr√πng ---
            parts = [x for x in [cse0_result, cse1_result, cse2_result] if x]
            if parts:
                merged = "\n\n".join(parts)

                # L·ªçc tr√πng link (Gi·ªØ nguy√™n)
                unique_lines = []
                seen_links = set()
                for line in merged.splitlines():
                    match = re.search(r"\(Ngu·ªìn: (.*?)\)", line)
                    if match:
                        link = match.group(1)
                        if link not in seen_links:
                            seen_links.add(link)
                            unique_lines.append(line)
                    else:
                        unique_lines.append(line)

                final_text = "\n".join(unique_lines)
                final_results.append(
                    f"### üîç K·∫øt qu·∫£ cho truy v·∫•n ph·ª•: {log_q}\n{final_text.strip()}"
                )

    # --- [4] G·ªôp to√†n b·ªô subquery l·∫°i ---
    if final_results:
        logger.info(f"Ho√†n t·∫•t t√¨m ki·∫øm {len(final_results)} subquery.")
        return "\n\n".join(final_results)

    logger.error("T·∫§T C·∫¢ 3 CSE + fallback FAIL.")
    return ""

# -------------------------------------------------------------------------
# CSE ƒê·ªòNG: m·ªói CSE c√≥ ID/API ri√™ng + offset kh√°c nhau ƒë·ªÉ tr√°nh tr√πng trang
# -------------------------------------------------------------------------
async def _search_cse(query, cse_id, api_key, index=0, start_idx=1):
    """T√¨m ki·∫øm b·∫±ng Google CSE c·ª• th·ªÉ, c√≥ th·ªÉ ch·ªânh offset ƒë·ªÉ tr√°nh tr√πng."""
    if not cse_id or not api_key:
        logger.warning(f"CSE{index} ch∆∞a c·∫•u h√¨nh ID/API key.")
        return ""

    params = {
        "key": api_key,
        "cx": cse_id,
        "q": query,
        "num": 3,
        "start": start_idx,  # tr√°nh tr√πng l·∫∑p trang k·∫øt qu·∫£ gi·ªØa c√°c CSE
        "gl": "vn",
        "hl": "en" if re.search(r"[a-zA-Z]{4,}", query) else "vi",
    }

    try:
        response = await asyncio.to_thread(
            requests.get,
            "https://www.googleapis.com/customsearch/v1",
            params=params,
            timeout=10,
        )
        data = response.json()

        if "items" not in data:
            logger.warning(f"CSE{index} kh√¥ng c√≥ k·∫øt qu·∫£ h·ª£p l·ªá cho query '{query[:60]}'")
            return ""

        relevant = []
        for item in data["items"][:3]:
            title = item.get("title", "Kh√¥ng c√≥ ti√™u ƒë·ªÅ")
            snippet_raw = item.get("snippet", "")
            snippet = (
                snippet_raw[:330] + "..." if len(snippet_raw) > 130 else snippet_raw
            )
            link = item.get("link", "")
            if any(ad in link.lower() for ad in ["shopee", "lazada", "amazon", "tiki"]):
                continue
            relevant.append(f"**{title}**: {snippet} (Ngu·ªìn: {link})")

        if relevant:
            logger.info(f"CSE{index} tr·∫£ v·ªÅ {len(relevant)} k·∫øt qu·∫£ h·ª£p l·ªá.")
            return f"**Search CSE{index} (Dynamic):**\n" + "\n".join(relevant) + "\n\n[D√ôNG ƒê·ªÇ TR·∫¢ L·ªúI E-GIRL, KH√îNG LEAK NGU·ªíN]"
        return ""

    except Exception as e:
        logger.error(f"CSE{index} l·ªói khi g·ªçi API: {e}")
        return ""


# -------------------------------------------------------------------------
# FALLBACK CHO CSE2
# -------------------------------------------------------------------------
async def _run_fallback_search(query):
    """Fallback xoay v√≤ng SerpAPI / Tavily / Exa n·∫øu CSE2 fail."""
    apis = ["SerpAPI", "Tavily", "Exa"]
    global SEARCH_API_COUNTER
    start_idx = SEARCH_API_COUNTER % 3
    SEARCH_API_COUNTER += 1

    for i in range(3):
        api_name = apis[(start_idx + i) % 3]
        try:
            if api_name == "SerpAPI" and SERPAPI_API_KEY:
                result = await _search_serpapi(query)
            elif api_name == "Tavily" and TAVILY_API_KEY:
                result = await _search_tavily(query)
            elif api_name == "Exa" and EXA_API_KEY:
                result = await _search_exa(query)
            else:
                continue

            if result:
                logger.info(f"Fallback {api_name} th√†nh c√¥ng cho query '{query[:60]}'")
                return result
            else:
                logger.warning(f"Fallback {api_name} r·ªóng ho·∫∑c l·ªói.")
        except Exception as e:
            logger.warning(f"Fallback {api_name} l·ªói: {e}")

    logger.error("T·∫§T C·∫¢ fallback APIs ƒë·ªÅu th·∫•t b·∫°i.")
    return ""


async def _search_serpapi(query):
    """SerpAPI: D√πng query c·ªßa Gemini, t·ªëi gi·∫£n h√≥a params."""
    if not SERPAPI_API_KEY: return ""
    
    params = {
        "q": query, # D√πng query T·ª™ GEMINI
        "api_key": SERPAPI_API_KEY,
        "engine": "google",
        "num": 3,
        "gl": "vn",
        "hl": "en" if re.search(r'[a-zA-Z]{4,}', query) else "vi" 
    }
    
    search = GoogleSearch(params)
    results = await asyncio.to_thread(search.get_dict)
    
    if 'organic_results' not in results:
        return ""
    
    # ... (Logic format k·∫øt qu·∫£ gi·ªØ nguy√™n) ...
    relevant = []
    for item in results['organic_results'][:3]:
        title = item.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')
        snippet = item.get('snippet', '')[:330] + "..." if len(item.get('snippet', '')) > 130 else item.get('snippet', '')
        link = item.get('link', '')
        if any(ad in link.lower() for ad in ['shopee', 'lazada', 'amazon', 'tiki']): continue
        relevant.append(f"**{title}**: {snippet} (Ngu·ªìn: {link})")
    
    return "**Search SerpAPI (Dynamic):**\n" + "\n".join(relevant) + "\n\n[D√ôNG ƒê·ªÇ TR·∫¢ L·ªúI E-GIRL, KH√îNG LEAK NGU·ªíN]" if relevant else ""

async def _search_tavily(query):
    """Tavily: D√πng query c·ªßa Gemini, client.search() c∆° b·∫£n."""
    if not TAVILY_API_KEY: return ""
    
    tavily = TavilyClient(api_key=TAVILY_API_KEY)
    params = {
        "query": query, # D√πng query T·ª™ GEMINI
        "search_depth": "basic", 
        "max_results": 3, 
        "include_answer": False
    }
    
    results = await asyncio.to_thread(tavily.search, **params)
    
    if 'results' not in results:
        return ""
    
    # ... (Logic format k·∫øt qu·∫£ gi·ªØ nguy√™n) ...
    relevant = []
    for item in results['results'][:3]:
        title = item.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')
        snippet = item.get('content', '')[:330] + "..." if len(item.get('content', '')) > 130 else item.get('content', '')
        link = item.get('url', '')
        if any(ad in link.lower() for ad in ['shopee', 'lazada', 'amazon', 'tiki']): continue
        relevant.append(f"**{title}**: {snippet} (Ngu·ªìn: {link})")
    
    return "**Search Tavily (Dynamic):**\n" + "\n".join(relevant) + "\n\n[D√ôNG ƒê·ªÇ TR·∫¢ L·ªúI E-GIRL, KH√îNG LEAK NGU·ªíN]" if relevant else ""

async def _search_exa(query):
    """Exa.ai: D√πng query c·ªßa Gemini, t√¨m ki·∫øm neural search c∆° b·∫£n."""
    if not EXA_API_KEY: return ""
    
    exa = exa_py.Exa(api_key=EXA_API_KEY)
    params = {
        "query": query, # D√πng query T·ª™ GEMINI
        "num_results": 3, 
        "use_autoprompt": True, 
        "type": "neural" # Neural search l√† ch·∫ø ƒë·ªô m·∫°nh nh·∫•t c·ªßa Exa
    }
    
    results = await asyncio.to_thread(exa.search, **params)
    
    if not results.results:
        return ""
    
    # ... (Logic format k·∫øt qu·∫£ gi·ªØ nguy√™n) ...
    relevant = []
    for item in results.results[:3]:
        title = item.title or 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ'
        snippet = item.text[:330] + "..." if len(item.text or '') > 130 else item.text or ''
        link = item.url
        if any(ad in link.lower() for ad in ['shopee', 'lazada', 'amazon', 'tiki']): continue
        relevant.append(f"**{title}**: {snippet} (Ngu·ªìn: {link})")
    
    return "**Search Exa.ai (Dynamic):**\n" + "\n".join(relevant) + "\n\n[D√ôNG ƒê·ªÇ TR·∫¢ L·ªúI E-GIRL, KH√îNG LEAK NGU·ªíN]" if relevant else ""

def run_calculator(equation):
    try:
        # R·∫•t nguy hi·ªÉm, ch·ªâ d√πng n·∫øu b·∫°n ki·ªÉm so√°t input r·∫•t ch·∫∑t
        # Gi·∫£ ƒë·ªãnh c√≥ th∆∞ vi·ªán to√°n h·ªçc an to√†n ·ªü ƒë√¢y
        import math
        return eval(equation, {"__builtins__": None}, math.__dict__)
    except Exception as e:
        return f"Calculation error: {str(e)}"

ALL_TOOLS = [
    Tool(function_declarations=[
        FunctionDeclaration(
            name="web_search",
            description=(
                "T√¨m ki·∫øm th√¥ng tin c·∫≠p nh·∫≠t (tin t·ª©c, gi√° c·∫£, phi√™n b·∫£n game, s·ª± ki·ªán) sau nƒÉm 2024. "
                "Ch·ªâ d√πng khi ki·∫øn th·ª©c n·ªôi b·ªô c·ªßa b·∫°n ƒë√£ l·ªói th·ªùi so v·ªõi ng√†y hi·ªán t·∫°i. "
                "Y√™u c·∫ßu T·ª∞ D·ªäCH c√¢u h·ªèi ti·∫øng Vi·ªát c·ªßa user th√†nh m·ªôt query t√¨m ki·∫øm ti·∫øng Anh T·ªêI ∆ØU."
            ),
            parameters={
                "type": "object",
                "properties": {"query": {"type": "string", "description": "C√¢u h·ªèi b·∫±ng ti·∫øng Anh"}},
                "required": ["query"]
            }
        )
    ]),
    Tool(function_declarations=[
        FunctionDeclaration(
            name="get_weather",
            description="L·∫•y th√¥ng tin th·ªùi ti·∫øt hi·ªán t·∫°i cho m·ªôt th√†nh ph·ªë c·ª• th·ªÉ.",
            parameters={
                "type": "object",
                "properties": {"city": {"type": "string", "description": "T√™n th√†nh ph·ªë, v√≠ d·ª•: 'Hanoi', 'Tokyo'."}},
                "required": ["city"]
            }
        )
    ]),
    Tool(function_declarations=[
        FunctionDeclaration(
            name="calculate",
            description="Gi·∫£i c√°c b√†i to√°n s·ªë h·ªçc ho·∫∑c bi·ªÉu th·ª©c ph·ª©c t·∫°p, bao g·ªìm c√°c h√†m l∆∞·ª£ng gi√°c, logarit, v√† ƒë·∫°i s·ªë.",
            parameters={
                "type": "object",
                "properties": {"equation": {"type": "string", "description": "Bi·ªÉu th·ª©c to√°n h·ªçc d∆∞·ªõi d·∫°ng string, v√≠ d·ª•: 'sin(pi/2) + 2*x'."}},
                "required": ["equation"]
            }
        )
    ]),
    Tool(function_declarations=[
        FunctionDeclaration(
            name="save_note",
            description="L∆∞u m·ªôt m·∫©u th√¥ng tin, ghi ch√∫ ho·∫∑c l·ªùi nh·∫Øc c·ª• th·ªÉ theo y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ b·∫°n c√≥ th·ªÉ truy c·∫≠p l·∫°i sau.",
            parameters={
                "type": "object",
                "properties": {"note": {"type": "string", "description": "N·ªôi dung ghi ch√∫ c·∫ßn l∆∞u."}},
                "required": ["note"]
            }
        )
    ]),
]

async def call_tool(function_call, user_id):
    name = function_call.name
    args = dict(function_call.args)
    logger.info(f"TOOL G·ªåI: {name} | Args: {args} | User: {user_id}")

    try:
        if name == "web_search":
            query = args.get("query", "")
            return await run_search_apis(query, "general")  # Gi·∫£ ƒë·ªãnh h√†m n√†y trong code g·ªëc, anh add n·∫øu c·∫ßn

        elif name == "get_weather":
            city = args.get("city", "Ho Chi Minh City")
            data = await get_weather(city)
            return json.dumps(data, ensure_ascii=False, indent=2)

        elif name == "calculate":
            eq = args.get("equation", "")
            return await asyncio.to_thread(run_calculator, eq)

        elif name == "save_note":
            note = args.get("note", "")
            return await save_note(note, user_id)

        else:
            return "Tool kh√¥ng t·ªìn t·∫°i!"

    except Exception as e:
        logger.error(f"Tool {name} l·ªói: {e}")
        return f"L·ªói tool: {str(e)}"

def normalize_city_name(city_query):
    # from config import CITY_NAME_MAP # ƒë√£ ƒë∆∞·ª£c di chuy·ªÉn l√™n tr√™n
    if not city_query:
        return ("Ho Chi Minh City", "Th√†nh ph·ªë H·ªì Ch√≠ Minh")
    city_key = city_query.strip().lower()
    for k, v in CITY_NAME_MAP.items():
        if k in city_key:
            return v
    return (city_query, city_query.title())